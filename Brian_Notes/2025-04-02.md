# üß† Retrieval Plugin + Postgres/pgvector Setup
These are my development notes for getting the [ChatGPT Retrieval Plugin](https://github.com/openai/chatgpt-retrieval-plugin) running with a local Postgres + pgvector setup. I'm documenting everything because my memory is terrible and I *will* forget all of this otherwise.

## ‚úÖ What I‚Äôve Done So Far

### üêç Python & Environment Setup

- I installed Python 3.10 using `pyenv`.
- I created a virtual environment using `poetry` and installed all project dependencies with `poetry install`.
- I added `python-dotenv` so I can load environment variables from a `.env` file without manually exporting them every time.
- In `main.py`, I added:

  ```python
  from dotenv import load_dotenv
  load_dotenv()
  ```

### üß† Retrieval Plugin Configuration

- I cloned the ChatGPT Retrieval Plugin repo.
- I created a `.env` file at the project root with the following values:

  ```env
  DATASTORE=postgres
  BEARER_TOKEN=your_token_here
  PG_HOST=localhost
  PG_PORT=5432
  PG_USER=myuser
  PG_PASSWORD=mypassword
  PG_DB=mydatabase
  ```

### üêò Postgres + pgvector Setup (Dockerized)

- I pulled the prebuilt Docker image:

  ```bash
  docker pull ankane/pgvector
  ```

- I started a Postgres container with pgvector enabled:

  ```bash
  docker run -e POSTGRES_USER=myuser \
             -e POSTGRES_PASSWORD=mypassword \
             -e POSTGRES_DB=mydatabase \
             --name my_postgres \
             -p 5432:5432 \
             -d ankane/pgvector
  ```

- I connected using `psql`:

  ```bash
  PGPASSWORD=mypassword psql -h localhost -p 5432 -U myuser -d mydatabase
  ```

- I enabled the pgvector extension manually:

  ```sql
  CREATE EXTENSION vector;
  ```

### üß± Database Schema Setup

- I ran the migration script included with the plugin to create the `documents` table and related indexes:

  ```bash
  psql -h localhost -p 5432 -U myuser -d mydatabase \
       -f examples/providers/supabase/migrations/20230414142107_init_pg_vector.sql
  ```

### üß™ Tests

- I scoped test runs to the Postgres backend only:

  ```bash
  poetry run pytest -s tests/datastore/providers/postgres/test_postgres_datastore.py
  ```

- I loaded env vars into the shell before running tests using:

  ```bash
  export $(cat .env | grep -v '^#' | xargs)
  ```

- All 8 tests passed üéâ

---

## üéØ Goal

My goal is to use the Retrieval Plugin with a local Postgres/pgvector backend to:

- Embed and upsert documents  
- Store and query vectors semantically  
- Optionally plug this into a frontend or custom GPT for retrieval-augmented generation (RAG)

I'm keeping everything local and minimal for now, but may swap out the vector store or deploy it later if this works well.

---
